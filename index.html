<!DOCTYPE html>
<html lang="en">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Abhinav Kumar</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/scrolling-nav.css" rel="stylesheet">

</head>

<body id="page-top">

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
    <div class="container">
      <a class="navbar-brand js-scroll-trigger" href="#page-top">Abhinav Kumar</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#about">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#projects">Projects</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#contact">Contact</a>
          </li>
          <li class="nav-item">
            <a target="_blank" class="nav-link js-scroll-trigger" href="resume.pdf">Resume</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <header class="bg-primary text-white">
    <div class="container text-center">
        <img src="pic.jpg" style="width:250px;height:250px;border-radius:50%">
      <h1>Abhinav Kumar</h1>
      <p class="lead">Welcome to my site! Hope you find something interesting.</p>
      
    </div>
  </header>

  <section id="about">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto">
          <h2>About Me</h2>
          <p class="lead">I am a senior at Georgia Tech majoring in Computer Science with Threads in Intelligence and Modeling and Simulation.</p>
          <h2>Interests</h2>
          <p class="lead">I hope to pursue a career in machine learning research focusing on creating AI agents that can interact with their environment, whether physical or virtual.
          </p>
          <p class="lead">Outside of working, I also enjoy hackathons, exercise, and science fiction/fantasy in all its forms. <b>Excelsior!</b></p>
          <br>
          <h2>Skills</h2>
          <ul>
            <li><b>Machine Learning/Deep Learning:</b> I have used machine learning technologies in my work experience as well as external projects. I have also given a presentation on Neural Style Transfer at a HackGT hosted workshop, organized a machine learning workshop held at HackGT 6 in October of 2019, and am involved in undergraduate research at Georgia Tech.</li>
            <li><b>Research Work:</b> I have been developing my research skills through participating in undergraduate research as well as doing research work as an intern at NASA.</li>
            <li><b>Leadership/Teamwork:</b> I have been fortunate to have been a part of and lead mltiple teams while working on various projects for HackGT, NASA, and undergraduate research. The soft skills I gained through those experiences have helped me greatly in improving how I work with others and increasing my productivity as well as my teammates'.</li>
          </ul>
        </div>
      </div>
    </div>
  </section>

  <section id="projects" class="bg-light">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto">
          <h2>Projects</h2>
          <ul>
            <li><b>NASA Intern Work: </b> I interned at NASA's Goddard Space Flight Center during the Spring and Summer semesters of 2020. I worked in the Goddard Earth Sciences (GES) Data and Information Services Center (DISC) on extracting important text variables from research papers. Using a pretrained BERT model and a dataset of natural disaster research papers, I was able to analyze BERT's attention ouputs to determine the most important keywords in the text. These results will be used in the future to construct a mapping between natural disasters and GES DISC's datasets to improve scientists' access to NASA resources.
            </li>
            <li><b>Deep Learning Research:</b> I am currently working with researchers at the Allen Institute for AI and the Max Planck Institute. The work I am doing is related to deep learning and symbolic languages with the goal being to explore ways to reduce computation time for common, intensive tasks by leveraging past experiences. I am also working on creating a dataset to faciliate analysis of Fermi problems.
            </li>
            <li><b>Robotics Research:</b> I am currently working in the Laboratory for Intelligent Decision and Autonomous Robots (LIDAR) at Georgia Tech on research related to trajectory optimization in systems with contact. This work is an opportunity for me to gain more experience in robotics as well as apply the machine learning techniques I have studied to a new domain.
            </li>            <!-- <li><b>Demand Forecasting:</b> During my final term at UPS, I worked on the team responsible for creating algorithms responsible for automating planning for UPS' line-haul truck movements. The specific portion I worked on was forecasting how many packages each facility would have to handle and send out on trucks. My contribution was to improve the quality of the data that was in use through using statistical changepoints to identify bad data, as well as improvements to the prediction process. I was able to implement a deep learning encoder decoder architecture for sequence to sequence time series prediction, which showed potential to improve prediction results. I was also able to create an analysis of locations that were only active during the holiday season that were unforecasted due to their high volatility and short running time. It was important to have forecasts for these locations because they handled large volumes of packages and we had no visibility to that as of yet. Through my analysis, I was able to create a protocol for analyzing these locations that is being built off of currently. I also improved the predictions for locations that lacked a significant history but still needed to be forecasted.</li>             -->
            <!-- <li><b>UPS Delay Analysis:</b> During my second semester working at UPS, I created a machine learning system to automatically analyze freight forwarding delays and rank their causes on a location by location basis. While there is a lot of work going on at UPS about reducing delays in the freight network, there was no system leveraging the analytical power of machine learning for this task. I created a pipeline that reads in data about historical shipments, trains a set of classifiers to predict different kinds of delays, and then uses those classifiers' decision criteria to rank what features of shipments were causing those delays. At that point, the system will write a report on the cause of these delays as well as create a SQL database and stored procedure for more detailed searching of shipment information. The stored procedure also gives the user the ability to analyze the correlation between different types of delays. This will be used to isolate and target problems in the UPS network and improve customers' service times.</li> -->
            <li><b><a href = "https://devpost.com/software/golden-gate">Golden Gate:</a></b> At TreeHacks 2019, my team created Golden Gate, a React and Express powered Chrome extension that reads news articles a user is currently viewing and suggests other related articles. In addition, the extension takes advantage of Google Cloud's NLP platform to perform sentiment analysis on these articles and provide an estimate of the bias present in the writing. It also extracts important entities in the text and links users to their Wikipedia pages. I personally handled the Express back-end as well as interfacing with and interpreting the results of Google Cloud's NLP API. I also did some work with the React front-end.</li>
        </ul>
        </div>
      </div>
    </div>
  </section>

  <section id="contact">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto">
          <h2>Contact me!</h2>
          <ul>
              <li><a target="blank" class="lead" href="https://www.linkedin.com/in/abhinavk99/">LinkedIn</a></li>
              <li><a target="blank" class="lead" href="https://github.com/abhinavkumar99">GitHub</a></li>
              <li><a target="blank" class="lead" href="mailto: akumar437@gatech.edu">Email</a></li>
              
              
          </ul>
        </div>
      </div>
    </div>
  </section>

  <!-- Footer -->
  <footer class="py-5 bg-dark">
    <div class="container">
      
    </div>
    <!-- /.container -->
  </footer>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

  <!-- Custom JavaScript for this theme -->
  <script src="js/scrolling-nav.js"></script>

</body>

</html>
